# Launch Post: r/javascript, r/webdev, r/reactjs

**Title**: I built a privacy-first emotion detection SDK that uses mouse movements instead of cameras

**Body**:

Hey everyone! ğŸ‘‹

I've been working on a project called **EmpathAI** â€“ a lightweight, privacy-focused SDK that detects user emotions (frustrated, focused, bored, happy, etc.) based purely on behavioral patterns like mouse movements, typing speed, and error rates.

**The Problem:**
Most emotion AI tools require camera access (facial recognition) or microphone access (voice analysis). This is intrusive, privacy-invasive, and honestly, users hate it.

**The Solution:**
EmpathAI analyzes *how* users interact with your app, not who they are.

- ğŸ–±ï¸ **Erratic mouse + high clicks** = Frustrated?
- âŒ¨ï¸ **Steady typing + low variance** = Focused?
- ğŸ¢ **Meandering mouse + inactivity** = Bored?

**Key Features:**
- ğŸ”’ **100% Privacy-First**: No video, no audio, no PII.
- ğŸš€ **Lightweight**: ~5KB (gzipped).
- âš›ï¸ **Framework Agnostic**: Works with React, Vue, Svelte, or Vanilla JS.
- âš¡ **Real-time**: Sub-second inference.

**Try the Demo**: [LINK TO YOUR DEMO]
**GitHub**: https://github.com/Pikxul/empathai
**NPM**: https://www.npmjs.com/package/empathai-core

It's fully open-source (MIT). I'd love to hear your feedback on the inference logic and potential use cases!

Cheers,
Piklu
